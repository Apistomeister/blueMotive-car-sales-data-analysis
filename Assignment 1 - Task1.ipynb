{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3382ce-43a3-4113-a09f-81edb4f318af",
   "metadata": {},
   "source": [
    "# Student ID: 24216779, API: BlueMotiveCars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8e0697-38e9-48e6-b754-b96ef922f80f",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e821a8-4df6-4f4f-bce2-7701a1e3e1ec",
   "metadata": {},
   "source": [
    "Let us start by importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32c27107-5cc5-4dfe-a980-bda6812889a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0f87c-55f2-444d-9364-2a60bb62f6e7",
   "metadata": {},
   "source": [
    "Helper Function to Get Total Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "476ae838-ccf6-4e11-8f7c-32eef275a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_pages_from_page(url):\n",
    "    \"\"\"\n",
    "    Given a URL, this function retrieves the total number of pages.\n",
    "    It first checks the <h2> header for text like \"Page 1 of 20\".\n",
    "    If that fails, it looks at the <nav> element for numeric page links.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching {url}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Try to extract the total pages from the header text.\n",
    "    h2 = soup.find('h2')\n",
    "    if h2:\n",
    "        # This regular expression looks for a pattern \"Page <number> of <total>\"\n",
    "        match = re.search(r'Page\\s+\\d+\\s+of\\s+(\\d+)', h2.get_text())\n",
    "        if match:\n",
    "            total_pages = int(match.group(1))\n",
    "            return total_pages\n",
    "    \n",
    "    # If the <h2> header did not contain the info, check the navigation bar.\n",
    "    nav = soup.find('nav')\n",
    "    if nav:\n",
    "        page_numbers = []\n",
    "        # Look through both <a> and <span> tags to collect numbers.\n",
    "        for tag in nav.find_all(['a', 'span']):\n",
    "            text = tag.get_text(strip=True)\n",
    "            if text.isdigit():\n",
    "                page_numbers.append(int(text))\n",
    "        if page_numbers:\n",
    "            return max(page_numbers)\n",
    "    \n",
    "    # If nothing works, return None.\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe37adc-e650-4011-b883-8e0d4bee4223",
   "metadata": {},
   "source": [
    "Function to Extract Data for a Single Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df8974e6-3b49-4b12-be7f-7011719c4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_brand_data(brand, first_page_url):\n",
    "    \"\"\"\n",
    "    Extract all car records for a given brand.\n",
    "    It first figures out the total pages available using the first page URL,\n",
    "    then loops through each page to collect the car details.\n",
    "    \"\"\"\n",
    "    print(f\"\\nStarting extraction for {brand}...\")\n",
    "    total_pages = get_total_pages_from_page(first_page_url)\n",
    "    if total_pages is None:\n",
    "        print(f\"Could not determine total pages for {brand} using {first_page_url}\")\n",
    "        return []\n",
    "    print(f\"Found {total_pages} pages for {brand}\")\n",
    "\n",
    "    # Create a URL template by replacing the page number part with a format placeholder.\n",
    "    # Assumes the URL ends with something like 'page01.html' which we can change.\n",
    "    base_url = re.sub(r'page\\d+\\.html', 'page{:02d}.html', first_page_url)\n",
    "    \n",
    "    records = []\n",
    "    # Loop through each page number from 1 to the total.\n",
    "    for page in range(1, total_pages + 1):\n",
    "        url = base_url.format(page)\n",
    "        print(f\"Processing {url}\")\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error processing {url}: {response.status_code}\")\n",
    "            continue\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find each car record within <li> tags.\n",
    "        li_items = soup.find_all('li')\n",
    "        for li in li_items:\n",
    "            record = {}\n",
    "            # Tag the record with the brand name.\n",
    "            record['Brand'] = brand\n",
    "            \n",
    "            # Extract make and model details from the <span> with class \"make-model\".\n",
    "            make_model_tag = li.find('span', class_='make-model')\n",
    "            if make_model_tag:\n",
    "                record['Make_Model'] = make_model_tag.get_text(strip=True)\n",
    "            \n",
    "            # The rest of the details are stored in a table with class \"car\".\n",
    "            table = li.find('table', class_='car')\n",
    "            if table:\n",
    "                for tr in table.find_all('tr'):\n",
    "                    cells = tr.find_all('td')\n",
    "                    if len(cells) == 2:\n",
    "                        # Remove extra characters (like \":\") from the field name.\n",
    "                        field = cells[0].get_text(strip=True).replace(\":\", \"\")\n",
    "                        value = cells[1].get_text(strip=True)\n",
    "                        record[field] = value\n",
    "            records.append(record)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d230d1f-465a-4665-8079-063e7320fa85",
   "metadata": {},
   "source": [
    "Function to Extract Data for All Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "667f8854-a7c2-4c4a-83ec-e34028133e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_data(brands_first_page):\n",
    "    \"\"\"\n",
    "    Loop through all the brands provided in the dictionary.\n",
    "    For each brand, extract all car sale records and combine them into a single list.\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    for brand, first_page_url in brands_first_page.items():\n",
    "        records = extract_brand_data(brand, first_page_url)\n",
    "        all_records.extend(records)\n",
    "    return all_records\n",
    "\n",
    "# You can test this with a small dictionary of brands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539bdbbf-cd3f-4036-8fa6-0620d67f944a",
   "metadata": {},
   "source": [
    "Function to Write Data to a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46f4ea56-737a-41b3-a803-fef9f0743a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(records, output_file):\n",
    "    \"\"\"\n",
    "    Write all the collected car records into a CSV file.\n",
    "    This function determines the header fields from the records and uses a preferred ordering.\n",
    "    \"\"\"\n",
    "    if not records:\n",
    "        print(\"No records found to write.\")\n",
    "        return\n",
    "\n",
    "    # Create a set of all keys present in the records.\n",
    "    fieldnames = set()\n",
    "    for rec in records:\n",
    "        fieldnames.update(rec.keys())\n",
    "    \n",
    "    # Define a preferred ordering for our columns.\n",
    "    ordering = ['Brand', 'Make_Model', 'Date of Sale', 'Sale Price', 'Year', 'Mileage', \n",
    "                'Classification', 'Transmission', 'Fuel Type', 'Description', 'Sale Location']\n",
    "    # Include any extra fields that might have been found.\n",
    "    fieldnames_ordered = [f for f in ordering if f in fieldnames] + [f for f in fieldnames if f not in ordering]\n",
    "    \n",
    "    # Write the records to the CSV file.\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames_ordered)\n",
    "        writer.writeheader()\n",
    "        for rec in records:\n",
    "            writer.writerow(rec)\n",
    "    print(f\"\\nData has been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccf3a28-e6d4-410c-8070-c697c6f8102b",
   "metadata": {},
   "source": [
    "Main Execution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "378a5f03-25f4-4174-af23-b98bc7e0f666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting extraction for Audi...\n",
      "Found 20 pages for Audi\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page01.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page02.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page03.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page04.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page05.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page06.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page07.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page08.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page09.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page10.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page11.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page12.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page13.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page14.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page15.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page16.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page17.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page18.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page19.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page20.html\n",
      "\n",
      "Starting extraction for BMW...\n",
      "Found 20 pages for BMW\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page01.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page02.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page03.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page04.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page05.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page06.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page07.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page08.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page09.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page10.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page11.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page12.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page13.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page14.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page15.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page16.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page17.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page18.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page19.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page20.html\n",
      "\n",
      "Starting extraction for Mercedes-Benz...\n",
      "Found 30 pages for Mercedes-Benz\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page01.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page02.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page03.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page04.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page05.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page06.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page07.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page08.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page09.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page10.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page11.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page12.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page13.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page14.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page15.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page16.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page17.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page18.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page19.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page20.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page21.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page22.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page23.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page24.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page25.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page26.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page27.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page28.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page29.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page30.html\n",
      "\n",
      "Starting extraction for Volkswagen...\n",
      "Found 17 pages for Volkswagen\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page01.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page02.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page03.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page04.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page05.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page06.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page07.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page08.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page09.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page10.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page11.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page12.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page13.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page14.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page15.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page16.html\n",
      "Processing http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page17.html\n",
      "\n",
      "Data has been saved to car_sales_data.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Define the first page URL for each car brand.\n",
    "    brands_first_page = {\n",
    "       \"Audi\": \"http://mlg.ucd.ie/modules/python/assignment1/cars/Audi-page01.html\",\n",
    "       \"BMW\": \"http://mlg.ucd.ie/modules/python/assignment1/cars/BMW-page01.html\",\n",
    "       \"Mercedes-Benz\": \"http://mlg.ucd.ie/modules/python/assignment1/cars/Mercedes-Benz-page01.html\",\n",
    "       \"Volkswagen\": \"http://mlg.ucd.ie/modules/python/assignment1/cars/Volkswagen-page01.html\"\n",
    "    }\n",
    "    \n",
    "    output_file = \"car_sales_data.csv\"\n",
    "    \n",
    "    # Extract all car records for all brands.\n",
    "    all_records = extract_all_data(brands_first_page)\n",
    "    \n",
    "    # Write the combined data to the CSV file.\n",
    "    write_to_csv(all_records, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a8e61-c977-4106-9b2f-a1af1e365c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
